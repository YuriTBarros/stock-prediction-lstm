# Stock Price Prediction com LSTM e MLOps

**Projeto de P√≥s-Gradua√ß√£o em Machine Learning**

Sistema completo de previs√£o de pre√ßos de a√ß√µes utilizando redes neurais LSTM (Long Short-Term Memory) com pipeline MLOps automatizado para experimenta√ß√£o, treinamento, deployment e monitoramento.

---

## üìã √çndice

1. [Vis√£o Geral](#vis√£o-geral)
2. [Arquitetura](#arquitetura)
3. [Tecnologias](#tecnologias)
4. [Pr√©-requisitos](#pr√©-requisitos)
5. [Instala√ß√£o](#instala√ß√£o)
6. [Execu√ß√£o](#execu√ß√£o)
7. [Uso da API](#uso-da-api)
8. [Workflows Automatizados](#workflows-automatizados)
9. [Notebooks](#notebooks)
10. [Estrutura do Projeto](#estrutura-do-projeto)
11. [M√©tricas do Modelo](#m√©tricas-do-modelo)
12. [Troubleshooting](#troubleshooting)

---

## üéØ Vis√£o Geral

Este projeto implementa um pipeline MLOps completo para previs√£o de s√©ries temporais financeiras, demonstrando a aplica√ß√£o pr√°tica de conceitos modernos de Machine Learning Operations em um problema real.

### Caracter√≠sticas Principais

- **Modelo LSTM** treinado com 7 anos de dados hist√≥ricos do SPY (S&P 500 ETF)
- **3 arquiteturas** testadas: LSTM simples, Stacked LSTM e BiLSTM
- **Grid Search** automatizado com 32 combina√ß√µes de hiperpar√¢metros
- **API REST** com FastAPI para predi√ß√µes e treinamento
- **Rastreamento de experimentos** com MLflow (58 experimentos hist√≥ricos)
- **Orquestra√ß√£o de workflows** com n8n para automa√ß√£o
- **Notifica√ß√µes em tempo real** via Discord
- **Containeriza√ß√£o completa** com Docker Compose
- **Modelo pr√©-treinado** pronto para uso (MAPE: 1.21%)

### Objetivos do Projeto

1. Demonstrar implementa√ß√£o de pipeline MLOps de ponta a ponta
2. Automatizar ciclo de vida de modelos de Machine Learning
3. Garantir reprodutibilidade e rastreabilidade de experimentos
4. Facilitar deployment e monitoramento de modelos em produ√ß√£o

---

## üèóÔ∏è Arquitetura

O sistema √© composto por 6 servi√ßos containerizados que trabalham em conjunto:

![Arquitetura do Sistema](images/architecture.png)

### Componentes

| Componente | Tecnologia | Porta | Fun√ß√£o |
| :--- | :--- | :---: | :--- |
| **API** | FastAPI | 8000 | Endpoints de predi√ß√£o e treinamento |
| **MLflow** | MLflow Server | 5000 | Rastreamento de experimentos e model registry |
| **n8n** | n8n Workflow | 5678 | Orquestra√ß√£o de workflows automatizados |
| **PostgreSQL** | PostgreSQL 15 | 5432 | Backend para MLflow e n8n |
| **Discord Proxy** | Flask | 9094 | Proxy para notifica√ß√µes Discord |
| **Prometheus** | Prometheus | 9090 | Monitoramento de m√©tricas (opcional) |

### Fluxo de Dados

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   n8n       ‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ Agenda treinamento/predi√ß√£o
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   API       ‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ Processa requisi√ß√µes
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂ Yahoo Finance (dados)
       ‚îÇ
       ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂ MLflow (tracking)
       ‚îÇ
       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂ Discord (notifica√ß√µes)
```

---

## üõ†Ô∏è Tecnologias

### Machine Learning
- **TensorFlow/Keras** - Framework de deep learning
- **scikit-learn** - Pr√©-processamento e m√©tricas
- **pandas/numpy** - Manipula√ß√£o de dados

### MLOps
- **MLflow** - Experiment tracking e model registry
- **n8n** - Workflow automation
- **Docker/Docker Compose** - Containeriza√ß√£o

### API e Backend
- **FastAPI** - Framework web moderno
- **PostgreSQL** - Banco de dados relacional
- **yfinance** - Dados financeiros do Yahoo Finance

### Monitoramento
- **Discord Webhooks** - Notifica√ß√µes em tempo real
- **Prometheus** - Coleta de m√©tricas (opcional)

---

## üìã Pr√©-requisitos

### Software Necess√°rio

- **Docker** (vers√£o 20.10 ou superior)
- **Docker Compose** (vers√£o 2.0 ou superior)
- **Git** (para clonar o reposit√≥rio)

### Opcional (para desenvolvimento)

- **Python 3.11+** (para executar notebooks)
- **Jupyter Notebook** (para explorar notebooks originais)

### Verificar Instala√ß√£o

```bash
# Verificar Docker
docker --version
# Sa√≠da esperada: Docker version 20.10.x ou superior

# Verificar Docker Compose
docker compose version
# Sa√≠da esperada: Docker Compose version v2.x.x ou superior
```

---

## üöÄ Instala√ß√£o

### Passo 1: Obter o Projeto

```bash
# Extrair o arquivo ZIP
unzip stock-prediction-mlops.zip
cd stock-prediction
```

### Passo 2: Configurar Vari√°veis de Ambiente (Opcional)

Para receber notifica√ß√µes no Discord, crie um arquivo `.env`:

```bash
# Criar arquivo .env
cat > .env << EOF
DISCORD_WEBHOOK_URL=https://discord.com/api/webhooks/SEU_WEBHOOK_AQUI
PORT=8000
EOF
```

**Como obter o webhook do Discord:**
1. Acesse seu servidor Discord
2. V√° em Configura√ß√µes do Canal ‚Üí Integra√ß√µes ‚Üí Webhooks
3. Clique em "Novo Webhook"
4. Copie a URL do webhook

### Passo 3: Verificar Estrutura

```bash
# Verificar arquivos principais
ls -l docker-compose.yml
ls -l notebooks/*.ipynb
ls -l notebooks/artifacts/best_model_final.keras
```

---

## ‚ñ∂Ô∏è Execu√ß√£o

### Iniciar Todos os Servi√ßos

```bash
# Iniciar em background
docker compose up -d

# Aguardar inicializa√ß√£o (30-60 segundos)
sleep 30

# Verificar status dos servi√ßos
docker compose ps
```

**Sa√≠da esperada:**
```
NAME                    STATUS    PORTS
stock-forecast-api      Up        0.0.0.0:8000->8000/tcp
mlops-mlflow            Up        0.0.0.0:5000->5000/tcp
mlops-n8n               Up        0.0.0.0:5678->5678/tcp
mlops-postgres          Up        0.0.0.0:5432->5432/tcp
discord-webhook-proxy   Up        0.0.0.0:9094->9094/tcp
```

### Acessar Interfaces Web

| Servi√ßo | URL | Descri√ß√£o |
| :--- | :--- | :--- |
| **API (Swagger)** | http://localhost:8000/docs | Documenta√ß√£o interativa da API |
| **MLflow UI** | http://localhost:5000 | Interface de experimentos |
| **n8n** | http://localhost:5678 | Editor de workflows |

### Verificar Sa√∫de da API

```bash
# Testar endpoint de health
curl http://localhost:8000/health

# Resposta esperada:
{
  "status": "healthy",
  "model_loaded": true,
  "model_path": "/app/notebooks/artifacts/best_model_final.keras"
}
```

### Parar os Servi√ßos

```bash
# Parar todos os servi√ßos
docker compose down

# Parar e remover volumes (cuidado: apaga dados)
docker compose down -v
```

---

## üîå Uso da API

A API oferece endpoints para predi√ß√£o e treinamento de modelos.

### 1. Fazer Predi√ß√£o

Use o modelo pr√©-treinado para fazer predi√ß√µes:

```bash
curl -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -d '{
    "values": [100,102,101,103,105,104,106,108,107,109,
                111,110,112,114,113,115,117,116,118,120,
                119,121,123,122,124,126,125,127,129,128,
                130,132,131,133,135,134,136,138,137,139,
                141,140,142,144,143,145,147,146,148,150,
                149,151,153,152,154,156,155,157,159,158],
    "horizon": 5
  }'
```

**Resposta:**
```json
{
  "predictions": [160.23, 161.45, 162.18, 163.02, 163.89],
  "model_info": {
    "lookback": 60,
    "features": ["close", "high", "low", "open", "volume"]
  }
}
```

### 2. Treinar Novo Modelo

Treinar um modelo com configura√ß√£o personalizada:

```bash
curl -X POST http://localhost:8000/train/single \
  -H "Content-Type: application/json" \
  -d '{
    "ticker": "SPY",
    "epochs": 50,
    "lookback": 60,
    "arch": "lstm",
    "hidden": 128,
    "dropout": 0.2
  }'
```

**Par√¢metros dispon√≠veis:**
- `ticker`: C√≥digo da a√ß√£o (ex: "SPY", "AAPL", "PETR4.SA")
- `epochs`: N√∫mero de √©pocas de treinamento (padr√£o: 50)
- `lookback`: Janela temporal de entrada (padr√£o: 60)
- `arch`: Arquitetura ("lstm", "stacked", "bilstm")
- `hidden`: Unidades LSTM (padr√£o: 128)
- `dropout`: Taxa de dropout (padr√£o: 0.2)

### 3. Grid Search

Executar busca de hiperpar√¢metros:

```bash
curl -X POST http://localhost:8000/train/grid \
  -H "Content-Type: application/json" \
  -d '{
    "ticker": "SPY"
  }'
```

Testa 32 combina√ß√µes:
- Lookback: 20, 40, 60
- Arquitetura: lstm, stacked, bilstm
- Hidden units: 64, 128
- Dropout: 0.2, 0.3

### 4. Verificar Status

```bash
# Health check
curl http://localhost:8000/health

# Informa√ß√µes do modelo
curl http://localhost:8000/model/info
```

---

## üîÑ Workflows Automatizados

O projeto inclui 5 workflows n8n para automa√ß√£o completa do ciclo de vida do modelo.

### Workflows Dispon√≠veis

| Workflow | Frequ√™ncia | Fun√ß√£o |
| :--- | :--- | :--- |
| **Grid Search** | Semanal (domingo 2h) | Busca de hiperpar√¢metros |
| **Treino R√°pido** | Di√°rio (6h) | Treinamento com 20 √©pocas |
| **Treino Automatizado** | Sob demanda | Treinamento completo |
| **Predi√ß√£o Di√°ria** | Di√°rio (9h) | Predi√ß√µes autom√°ticas |
| **Monitoramento** | A cada 5 min | Health check da API |

### Configurar Workflows

1. **Acessar n8n:**
   ```
   http://localhost:5678
   ```

2. **Importar workflows:**
   - Clique em "Import from File"
   - Selecione arquivos da pasta `workflows/`
   - Importe os 5 arquivos JSON

3. **Ativar workflows:**
   - Abra cada workflow
   - Clique no toggle "Active" no canto superior direito

### Testar Workflow Manualmente

1. Abra o workflow desejado
2. Clique em "Execute Workflow"
3. Acompanhe a execu√ß√£o em tempo real
4. Verifique notifica√ß√µes no Discord (se configurado)

### Estrutura de Notifica√ß√µes

Cada workflow envia 3 tipos de notifica√ß√µes:

- **üöÄ In√≠cio** - Workflow iniciado
- **‚úÖ Sucesso** - Execu√ß√£o conclu√≠da com sucesso
- **‚ùå Erro** - Falha na execu√ß√£o com detalhes

---

## üìì Notebooks

O projeto inclui 2 notebooks Jupyter que documentam todo o processo de desenvolvimento.

### Notebooks Dispon√≠veis

#### 1. data_exploration.ipynb

An√°lise explorat√≥ria dos dados:
- Carregamento de dados do Yahoo Finance
- Estat√≠sticas descritivas
- Visualiza√ß√µes de s√©ries temporais
- Verifica√ß√£o de qualidade (valores nulos, outliers)
- Tratamento de MultiIndex

#### 2. lstm_model.ipynb

Desenvolvimento completo do modelo:
- Constru√ß√£o de arquiteturas LSTM
- Grid search de hiperpar√¢metros
- Treinamento com callbacks (EarlyStopping, ReduceLROnPlateau)
- Avalia√ß√£o em conjunto de teste
- An√°lise de res√≠duos
- Salvamento de artefatos

### Executar Notebooks

```bash
# Instalar Jupyter (se necess√°rio)
pip install jupyter notebook pandas matplotlib

# Navegar at√© a pasta
cd notebooks

# Iniciar Jupyter
jupyter notebook

# Abrir no navegador:
# http://localhost:8888
```

### Artifacts Gerados

Os notebooks geram artefatos na pasta `notebooks/artifacts/`:

- `best_model_final.keras` - Modelo treinado
- `scaler_x_final.joblib` - Scaler de features
- `scaler_y_final.joblib` - Scaler do target
- `summary_final.json` - Configura√ß√£o do modelo
- `reports/` - Visualiza√ß√µes e resultados

---

## üìÇ Estrutura do Projeto

```
stock-prediction/
‚îÇ
‚îú‚îÄ‚îÄ README.md                    # Este arquivo
‚îÇ
‚îú‚îÄ‚îÄ notebooks/                   # Jupyter Notebooks originais
‚îÇ   ‚îú‚îÄ‚îÄ data_exploration.ipynb   # An√°lise explorat√≥ria
‚îÇ   ‚îú‚îÄ‚îÄ lstm_model.ipynb         # Desenvolvimento do modelo
‚îÇ   ‚îî‚îÄ‚îÄ artifacts/               # Artefatos gerados
‚îÇ       ‚îú‚îÄ‚îÄ best_model_final.keras
‚îÇ       ‚îú‚îÄ‚îÄ scaler_x_final.joblib
‚îÇ       ‚îú‚îÄ‚îÄ scaler_y_final.joblib
‚îÇ       ‚îú‚îÄ‚îÄ summary_final.json
‚îÇ       ‚îî‚îÄ‚îÄ reports/             # Visualiza√ß√µes e CSVs
‚îÇ
‚îú‚îÄ‚îÄ api/                         # API FastAPI
‚îÇ   ‚îú‚îÄ‚îÄ main.py                  # Endpoints da API
‚îÇ   ‚îî‚îÄ‚îÄ utils.py                 # Fun√ß√µes utilit√°rias
‚îÇ
‚îú‚îÄ‚îÄ src/                         # C√≥digo fonte
‚îÇ   ‚îú‚îÄ‚îÄ data_ingestion.py        # Download de dados
‚îÇ   ‚îú‚îÄ‚îÄ my_model_lib.py          # Arquiteturas LSTM
‚îÇ   ‚îî‚îÄ‚îÄ train.py                 # Pipeline de treinamento
‚îÇ
‚îú‚îÄ‚îÄ workflows/                   # Workflows n8n
‚îÇ   ‚îú‚îÄ‚îÄ grid_search.json
‚îÇ   ‚îú‚îÄ‚îÄ treino_rapido.json
‚îÇ   ‚îú‚îÄ‚îÄ treino_automatizado.json
‚îÇ   ‚îú‚îÄ‚îÄ predicao_diaria.json
‚îÇ   ‚îî‚îÄ‚îÄ monitoramento.json
‚îÇ
‚îú‚îÄ‚îÄ data/                        # Dados locais
‚îÇ   ‚îî‚îÄ‚îÄ SPY_data.parquet         # 7 anos de dados hist√≥ricos
‚îÇ
‚îú‚îÄ‚îÄ mlruns/                      # Hist√≥rico MLflow
‚îÇ   ‚îî‚îÄ‚îÄ [58 experimentos]
‚îÇ
‚îú‚îÄ‚îÄ mlartifacts/                 # Artefatos MLflow
‚îÇ
‚îú‚îÄ‚îÄ dockerfiles/                 # Dockerfiles
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile               # API
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile.mlflow        # MLflow
‚îÇ   ‚îî‚îÄ‚îÄ Dockerfile.postgres      # PostgreSQL
‚îÇ
‚îú‚îÄ‚îÄ discord-webhook-proxy/       # Proxy Discord
‚îÇ   ‚îî‚îÄ‚îÄ app.py
‚îÇ
‚îú‚îÄ‚îÄ docker-compose.yml           # Orquestra√ß√£o
‚îú‚îÄ‚îÄ requirements.txt             # Depend√™ncias Python
‚îî‚îÄ‚îÄ .env                         # Vari√°veis de ambiente (criar)
```

---

## üìä M√©tricas do Modelo

### Modelo Pr√©-Treinado

O modelo inclu√≠do foi treinado com a seguinte configura√ß√£o:

| Par√¢metro | Valor |
| :--- | :--- |
| **Arquitetura** | LSTM Simples |
| **Lookback** | 60 dias |
| **Hidden Units** | 128 |
| **Dropout** | 0.2 |
| **√âpocas** | 50 |
| **Batch Size** | 32 |
| **Learning Rate** | 0.001 |

### Resultados no Conjunto de Teste

| M√©trica | Valor | Descri√ß√£o |
| :--- | ---: | :--- |
| **MAE** | 7.01 | Erro absoluto m√©dio |
| **RMSE** | 10.02 | Raiz do erro quadr√°tico m√©dio |
| **MAPE** | 1.21% | Erro percentual absoluto m√©dio |

### Hist√≥rico de Experimentos

O projeto inclui **58 experimentos** rastreados no MLflow:

- **Experimento 1:** `lstm-spy-grid` (~55 runs)
  - Grid search com m√∫ltiplas configura√ß√µes
  - Varia√ß√µes de lookback, arquitetura, learning rate, hidden units, dropout

- **Experimento 2:** `lstm-spy-final` (~3 runs)
  - Treinamento final com melhor configura√ß√£o
  - Modelo com melhor RMSE selecionado

### Visualizar no MLflow

```bash
# Acessar MLflow UI
http://localhost:5000

# Navegar para:
# - "Experiments" para ver todos os experimentos
# - Selecionar m√∫ltiplos runs para comparar
# - Ver gr√°ficos de m√©tricas e par√¢metros
```

---

## üîß Troubleshooting

### Problema: API n√£o inicia

**Sintomas:**
```
Error: Cannot connect to API at localhost:8000
```

**Solu√ß√µes:**

1. Verificar se o container est√° rodando:
```bash
docker compose ps
docker compose logs api
```

2. Verificar porta ocupada:
```bash
# Linux/Mac
lsof -i :8000

# Windows
netstat -ano | findstr :8000
```

3. Reiniciar servi√ßo:
```bash
docker compose restart api
```

### Problema: Modelo n√£o carregado

**Sintomas:**
```json
{
  "status": "healthy",
  "model_loaded": false
}
```

**Solu√ß√µes:**

1. Verificar se o modelo existe:
```bash
ls -lh notebooks/artifacts/best_model_final.keras
```

2. Treinar novo modelo:
```bash
curl -X POST http://localhost:8000/train/single \
  -H "Content-Type: application/json" \
  -d '{"ticker": "SPY", "epochs": 50}'
```

### Problema: Yahoo Finance n√£o responde

**Sintomas:**
```
Failed to get ticker 'SPY' reason: JSONDecodeError
```

**Solu√ß√µes:**

1. **Use o modelo pr√©-treinado** (n√£o precisa treinar):
```bash
curl -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -d '{"values": [100,102,...,158], "horizon": 5}'
```

2. **Aguarde e tente novamente** (Yahoo Finance pode estar temporariamente indispon√≠vel)

3. **Use dados locais** (j√° inclu√≠dos):
```bash
# Os dados locais em data/SPY_data.parquet s√£o usados automaticamente
# se o Yahoo Finance falhar
```

### Problema: Discord n√£o recebe notifica√ß√µes

**Solu√ß√µes:**

1. Verificar webhook configurado:
```bash
cat .env | grep DISCORD_WEBHOOK_URL
```

2. Testar webhook:
```bash
curl -X POST http://localhost:9094/test
```

3. Configurar webhook (se n√£o configurado):
```bash
echo "DISCORD_WEBHOOK_URL=https://discord.com/api/webhooks/SEU_WEBHOOK" > .env
docker compose restart
```

### Problema: MLflow n√£o mostra experimentos

**Solu√ß√µes:**

1. Verificar se o PostgreSQL est√° rodando:
```bash
docker compose ps postgres
```

2. Verificar logs do MLflow:
```bash
docker compose logs mlflow
```

3. Reiniciar MLflow:
```bash
docker compose restart mlflow
```

### Problema: n8n n√£o executa workflows

**Solu√ß√µes:**

1. Verificar se os workflows est√£o ativos:
   - Abra http://localhost:5678
   - Verifique toggle "Active" em cada workflow

2. Verificar credenciais:
   - Workflows usam HTTP simples (sem autentica√ß√£o)
   - Verificar URLs: `http://api:8000` (dentro do Docker)

3. Testar manualmente:
   - Abra o workflow
   - Clique em "Execute Workflow"
   - Veja erros no painel de execu√ß√£o

### Logs √öteis

```bash
# Ver logs de todos os servi√ßos
docker compose logs -f

# Ver logs de um servi√ßo espec√≠fico
docker compose logs -f api
docker compose logs -f mlflow
docker compose logs -f n8n

# Ver √∫ltimas 100 linhas
docker compose logs --tail=100 api
```

---

## üéì Uso Acad√™mico

Este projeto foi desenvolvido como parte de uma p√≥s-gradua√ß√£o em Machine Learning e pode ser usado para:

### Apresenta√ß√µes
- Demonstrar pipeline MLOps completo
- Mostrar experimenta√ß√£o sistem√°tica
- Explicar decis√µes de arquitetura

### Aprendizado
- Estudar c√≥digo limpo e modular
- Entender boas pr√°ticas de MLOps
- Explorar notebooks com an√°lises detalhadas

### Extens√µes Poss√≠veis
- Adicionar mais features (indicadores t√©cnicos)
- Testar outras arquiteturas (GRU, Transformer)
- Implementar ensemble de modelos
- Adicionar backtesting
- Criar dashboard de visualiza√ß√£o

---

## üìö Refer√™ncias

- **FastAPI:** https://fastapi.tiangolo.com/
- **MLflow:** https://mlflow.org/
- **n8n:** https://n8n.io/
- **TensorFlow:** https://www.tensorflow.org/
- **Docker:** https://www.docker.com/
- **LSTM Paper:** Hochreiter, S., & Schmidhuber, J. (1997). Long short-term memory. *Neural computation*, 9(8), 1735-1780.

---

## üìÑ Licen√ßa

Este projeto √© desenvolvido para fins acad√™micos e educacionais.

---

## üë§ Autor

Projeto desenvolvido como parte de P√≥s-Gradua√ß√£o em Machine Learning.

---

## üöÄ Quick Start

```bash
# 1. Extrair projeto
unzip stock-prediction.zip
cd stock-prediction

# 2. Iniciar servi√ßos
docker compose up -d

# 3. Aguardar inicializa√ß√£o
sleep 30

# 4. Testar API
curl http://localhost:8000/health

# 5. Fazer predi√ß√£o
curl -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -d '{"values": [100,102,101,103,105,104,106,108,107,109,111,110,112,114,113,115,117,116,118,120,119,121,123,122,124,126,125,127,129,128,130,132,131,133,135,134,136,138,137,139,141,140,142,144,143,145,147,146,148,150,149,151,153,152,154,156,155,157,159,158], "horizon": 5}'

# 6. Acessar interfaces
# API: http://localhost:8000/docs
# MLflow: http://localhost:5000
# n8n: http://localhost:5678
```

**Pronto! O sistema est√° funcionando.** üéâ
